apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: music-therapy-classifier
  namespace: kserve-models
  labels:
    app: music-therapy-model
    version: v1
  annotations:
    serving.kserve.io/deploymentMode: RawDeployment
spec:
  predictor:
    serviceAccountName: kserve-sa
    minReplicas: 1
    maxReplicas: 3
    scaleTarget: 70 # Target CPU utilization percentage
    scaleMetric: cpu
    containerConcurrency: 10
    timeout: 60
    canaryTrafficPercent: 20 # Canary deployment: 20% to new version
    sklearn:
      storageUri: "s3://mlflow-bucket/models/music-therapy-classifier/1/"
      resources:
        requests:
          cpu: 100m
          memory: 512Mi
        limits:
          cpu: 1
          memory: 2Gi
      env:
        - name: MLFLOW_TRACKING_URI
          value: "http://mlflow-service.mlflow:5000"
        - name: MODEL_NAME
          value: "music-therapy-classifier"
        - name: MODEL_VERSION
          value: "1"
        # Custom model serving configuration
        - name: WORKERS
          value: "2"
        - name: MAX_ASYNCIO_WORKERS
          value: "10"
---
# Alternative PyTorch/Custom model serving configuration
apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: music-therapy-pytorch
  namespace: kserve-models
  labels:
    app: music-therapy-model
    version: v2
    framework: pytorch
spec:
  predictor:
    serviceAccountName: kserve-sa
    minReplicas: 1
    maxReplicas: 5
    pytorch:
      storageUri: "s3://mlflow-bucket/models/music-therapy-pytorch/1/"
      resources:
        requests:
          cpu: 200m
          memory: 1Gi
        limits:
          cpu: 2
          memory: 4Gi
      env:
        - name: TS_MODEL_STORE
          value: "/mnt/models"
        - name: TS_LOAD_MODELS
          value: "music_therapy_model=music_therapy_model.mar"
---
# Custom predictor with custom container
apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: music-therapy-custom
  namespace: kserve-models
  labels:
    app: music-therapy-model
    version: v3
    type: custom
spec:
  predictor:
    serviceAccountName: kserve-sa
    minReplicas: 2
    maxReplicas: 10
    scaleTarget: 80
    containers:
      - name: kserve-container
        image: music-therapy/model-server:latest
        ports:
          - containerPort: 8080
            protocol: TCP
        env:
          - name: MLFLOW_TRACKING_URI
            value: "http://mlflow-service.mlflow:5000"
          - name: MODEL_NAME
            value: "music-therapy-classifier"
          - name: STORAGE_URI
            value: "s3://mlflow-bucket/models/"
        resources:
          requests:
            cpu: 200m
            memory: 512Mi
          limits:
            cpu: 1
            memory: 2Gi
        livenessProbe:
          httpGet:
            path: /v1/models/music-therapy-classifier
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /v1/models/music-therapy-classifier
            port: 8080
          initialDelaySeconds: 10
          periodSeconds: 5
---
# Traffic routing and canary deployment configuration
apiVersion: serving.kserve.io/v1alpha1
kind: TrafficPolicy
metadata:
  name: music-therapy-traffic
  namespace: kserve-models
spec:
  default:
    canary:
      - revision: music-therapy-classifier-v1
        percent: 80
      - revision: music-therapy-classifier-v2
        percent: 20
  targets:
    - revisionName: music-therapy-classifier-v1
      percent: 80
    - revisionName: music-therapy-classifier-v2
      percent: 20
---
# HPA for auto-scaling based on custom metrics
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: music-therapy-hpa
  namespace: kserve-models
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: music-therapy-classifier-predictor
  minReplicas: 1
  maxReplicas: 10
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 80
    - type: Pods
      pods:
        metric:
          name: inference_requests_per_second
        target:
          type: AverageValue
          averageValue: "50"
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
        - type: Percent
          value: 10
          periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
        - type: Percent
          value: 50
          periodSeconds: 30
        - type: Pods
          value: 2
          periodSeconds: 60
